{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc06d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c42717",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        # --- Encoder ---\n",
    "        # Entrada: (B, 3, 256, 256)\n",
    "        self.encoder = nn.Sequential(\n",
    "            # 1ª Camada: (B, 3, 256, 256) -> (B, 16, 128, 128)\n",
    "            nn.Conv2d(3, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # 2ª Camada: (B, 16, 128, 128) -> (B, 32, 64, 64)\n",
    "            nn.Conv2d(16, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # 3ª Camada: (B, 32, 64, 64) -> (B, 64, 32, 32)\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # 4ª Camada: (B, 64, 32, 32) -> (B, 128, 16, 16)\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # 5ª Camada: (B, 128, 16, 16) -> (B, 128, 8, 8)\n",
    "            nn.Conv2d(128, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(True)\n",
    "            # Fim do Encoder. Saída é o espaço latente (128, 8, 8)\n",
    "        )\n",
    "        \n",
    "        # --- Decoder ---\n",
    "        # Entrada: (B, 128, 8, 8)\n",
    "        self.decoder = nn.Sequential(\n",
    "            # 1ª Camada: (B, 128, 8, 8) -> (B, 128, 16, 16)\n",
    "            nn.ConvTranspose2d(128, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # 2ª Camada: (B, 128, 16, 16) -> (B, 64, 32, 32)\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # 3ª Camada: (B, 64, 32, 32) -> (B, 32, 64, 64)\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # 4ª Camada: (B, 32, 64, 64) -> (B, 16, 128, 128)\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # 5ª Camada: (B, 16, 128, 128) -> (B, 3, 256, 256)\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid() # Saída da imagem normalizada entre [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        latent_vector = encoded \n",
    "        decoded = self.decoder(latent_vector)\n",
    "        return decoded, latent_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d8bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = './places365_data'\n",
    "\n",
    "dataset = datasets.Places365(\n",
    "    root=data_root,\n",
    "    split='val',              # Split: 'train-standard', 'train-challenge', or 'val'\n",
    "    small=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19619f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "model = AutoEncoder().to(device)\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f\"\\nModel initialized and sent to {device}.\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 4B. The Training Function ---\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    training_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch_idx, (data, _) in enumerate(dataloader):\n",
    "            data = data.to(device)\n",
    "            reconstructed, _ = model(data)\n",
    "            loss = criterion(reconstructed, data)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()s\n",
    "            \n",
    "            epoch_loss += loss.item() * data.size(0)\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx}/{len(dataloader)}], Loss: {loss.item():.6f}')\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / len(dataset)\n",
    "        training_losses.append(avg_epoch_loss)\n",
    "        print(f\"--- Epoch {epoch+1} finished. Average Loss: {avg_epoch_loss:.6f} ---\")\n",
    "        \n",
    "    return training_losses\n",
    "\n",
    "training_losses = train_model(model, dataloader, criterion, optimizer, EPOCHS)\n",
    "\n",
    "print(\"\\nTraining complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d272d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f\"models/model-v1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
